{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#from taking n purest pixels \n",
    "purest_pixels_dict = np.load('./purest_pixels_dict.npy').item()\n",
    "\n",
    "#from subtracting out signal from background\n",
    "pure_signal_dict = np.load('./pure_signal_dict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://evols.library.manoa.hawaii.edu/bitstream/handle/10524/35872/vol3-Poop-Que(LO).pdf#page=11\n",
    "#Olivenza: Took average for LL chondrite \n",
    "#'H' has about 25-30% total Iron (with over half in metallic form =>strongly magnetic)\n",
    "#L contains 20-25% (with 5-10% in uncombined metal state)\n",
    "#'LL' contain 19-22% iron (with only 0.3-3% metallic iron)\n",
    "CLASSIFICATION_PER_SPECIMEN =  {'Abee':'EH4', 'Acapulco':'Acapulcoite', 'Allende':'CV3','Brownsfield':'H3.7',\n",
    "                                'Estacado':'H6', 'Estacado2':'H6', 'Gibeon':'IronIva', 'Hessle':'H5', \n",
    "                                'Holbrook':\"L/LL6\", 'Homestead':'L5','Homestead2':'L5','Millbilille':'Eucrite-mmict',\n",
    "                                'Olivenza':\"LL5\", 'Peekshill':'H6',\n",
    "                                'PutnamCounty':'IronIva', 'Soku':'LL4', 'Steinbach1':'IronIva', 'Steinbach2':'IronIva', \n",
    "                                'Sutton':'H5','Toluca1':'IronIAB-sLL', 'Toluca2':'IronIAB-sLL', 'Toluca3':'IronIAB-sLL', \n",
    "                                'TolucaBig':'IronIAB-sLL'}\n",
    "\n",
    "IRON_CATEGORY_PER_SPECIMEN = {'Abee':32.52, 'Acapulco':27.5, 'Allende':23.85,'Brownsfield':'H','Estacado':27.88, \n",
    "                                'Estacado2':27.88, 'Gibeon':91.8, 'Hessle':'H', 'Holbrook':\"L/LL\", 'Homestead':'L',\n",
    "                                'Homestead2':'L','Millbilille':'L','Olivenza':\"LL\", 'Peekshill':'H',\n",
    "                                'PutnamCounty':91.57, 'Soku':'LL', 'Steinbach1':'HH', 'Steinbach2':'HH', 'Sutton':'H', \n",
    "                                'Toluca1':91, 'Toluca2':91, 'Toluca3':91, 'TolucaBig':91}\n",
    "\n",
    "IRON_ALL_CATEGORIZED = {'Abee':'H', 'Acapulco':'H', 'Allende':'L','Brownsfield':'H','Estacado':'H', \n",
    "                                'Estacado2':'H', 'Gibeon':'HH', 'Hessle':'H', 'Holbrook':\"L/LL\", 'Homestead':'L',\n",
    "                                'Homestead2':'L','Millbilille':'L','Olivenza':\"LL\", 'Peekshill':'H',\n",
    "                                'PutnamCounty':'H', 'Soku':'LL', 'Steinbach1':'HH', 'Steinbach2':'HH', 'Sutton':'H', \n",
    "                                'Toluca1':'HH', 'Toluca2':'HH', 'Toluca3':'HH', 'TolucaBig':'HH'}\n",
    "\n",
    "IRON_SIMPLE_CATEGORIZED = {'Abee':'L', 'Acapulco':'L', 'Allende':'L','Brownsfield':'L','Estacado':'L', \n",
    "                                'Estacado2':'L', 'Gibeon':'HH', 'Hessle':'L', 'Holbrook':\"L\", 'Homestead':'L',\n",
    "                                'Homestead2':'L','Millbilille':'L','Olivenza':\"L\", 'Peekshill':'L',\n",
    "                                'PutnamCounty':'L', 'Soku':'L', 'Steinbach1':'HH', 'Steinbach2':'HH', 'Sutton':'', \n",
    "                                'Toluca1':'HH', 'Toluca2':'HH', 'Toluca3':'HH', 'TolucaBig':'HH'}\n",
    "\n",
    "IRON_PERCENTAGE_IF_AVAILABLE = {'Abee':32.52, 'Acapulco':27.5, 'Allende':23.85,'Estacado':27.88, \n",
    "                                'Estacado2':27.88, 'Gibeon':91.8, 'PutnamCounty':91.57,'Toluca1':91, \n",
    "                                'Toluca2':91, 'Toluca3':91, 'TolucaBig':91}\n",
    "COLORS = {'Abee':'darkslateblue', 'Acapulco':'green', 'Allende':'blue','Brownsfield':'yellow',\n",
    "                                'Estacado':'purple', 'Estacado2':'brown', 'Gibeon':'black', 'Hessle':'lime', \n",
    "                                'Holbrook':\"orange\", 'Homestead':'grey','Homestead2':'lightgreen',\n",
    "                                  'Millbilille':'lightcoral',\n",
    "                                'Olivenza':\"c\", 'Peekshill':'cyan',\n",
    "                                'PutnamCounty':'pink', 'Soku':'silver', 'Steinbach1':'maroon', 'Steinbach2':'fuchsia', \n",
    "                                'Sutton':'lawngreen','Toluca1':'cyan', 'Toluca2':'ivory', 'Toluca3':'olive', \n",
    "                                'TolucaBig':'red'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 6)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "#create matrix of all data samples (no classes)\n",
    "all_data = []\n",
    "all_data_simplified_classes = []\n",
    "all_data_standard_classes = []\n",
    "simplified_classes = ['HH','L']\n",
    "standard_classes = ['HH','H','L','L/LL','LL']\n",
    "all_data_meteorite_classes = []\n",
    "\n",
    "for sample in pure_signal_dict: \n",
    "    if sample == 'TolucaBig':\n",
    "        continue\n",
    "    for row in pure_signal_dict[sample]: \n",
    "        all_data.append(row)\n",
    "        all_data_simplified_classes.append(IRON_SIMPLE_CATEGORIZED[sample])\n",
    "        all_data_standard_classes.append(IRON_ALL_CATEGORIZED[sample])\n",
    "        all_data_meteorite_classes.append(sample)\n",
    "\n",
    "print np.shape(all_data)\n",
    "print np.shape(all_data_simplified_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 6)\n"
     ]
    }
   ],
   "source": [
    "all_data_mean = []\n",
    "all_data_mean_classes = []\n",
    "for sample in pure_signal_dict: \n",
    "    all_data_mean.append(np.mean(pure_signal_dict[sample], axis=0))\n",
    "    all_data_mean_classes.append(sample)\n",
    "    \n",
    "print np.shape(all_data_mean)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "band = [610,680,730,760,810,860]\n",
    "\n",
    "def add_many_variables(spectrum):\n",
    "    pairs = list(itertools.combinations(spectrum, 2))\n",
    "  \n",
    "    \n",
    "    differences = [abs(b-a) for (a,b) in pairs]\n",
    "    differences_squared = [abs(b-a)**2 for (a,b) in pairs]\n",
    " \n",
    "    ratios = [float(b)/float(a) for (a,b) in pairs]\n",
    "    ratios_squared = [(float(b)/float(a))**2 for (a,b) in pairs]\n",
    "    return spectrum\n",
    "    #return np.concatenate((spectrum,differences))\n",
    "    #return np.concatenate((spectrum,differences))\n",
    "    #return ratios\n",
    "    #based on expected iron changes\n",
    "    #return [spectrum[0],spectrum[1],spectrum[5]]\n",
    "    #return np.concatenate((spectrum,differences,ratios))\n",
    "    #sums \n",
    "    #slopes = [(b-a)/(band[i] for i, (a,b) in enumerate(pairs)]\n",
    "#NOTE: tried a bunch of stuff. Seemed like just using the spectrum itself worked best, though it would be \n",
    "#nice in partiuclar to pay attention to the ratio results since this helps get rid of any noise across all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 6)\n",
      "(210, 6)\n"
     ]
    }
   ],
   "source": [
    "mega_feature_array = []\n",
    "\n",
    "def build_mega_feature_array(original_dataset): \n",
    "    for sample in original_dataset: \n",
    "        mega_feature_array.append(add_many_variables(sample))\n",
    "\n",
    "build_mega_feature_array(all_data)\n",
    "  \n",
    "print np.shape(all_data_mean)\n",
    "print np.shape(mega_feature_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 6)\n",
      "(210, 2)\n",
      "[ 0.9663401   0.01862728]\n",
      "[[ 0.45376862  0.28069435  0.42974882  0.4357943   0.4071484   0.41825135]\n",
      " [-0.29418417  0.04692671 -0.46340287 -0.20834964  0.20448104  0.7818499 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=2)\n",
    "print np.shape(mega_feature_array)\n",
    "data_r = sklearn_pca.fit_transform(mega_feature_array)\n",
    "print np.shape(data_r)\n",
    "print sklearn_pca.explained_variance_ratio_\n",
    "print sklearn_pca.components_\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for i, row in enumerate(data_r): \n",
    "    if all_data_standard_classes[i] == 'HH': \n",
    "        plt.scatter(row[0],row[1], color='red')\n",
    "    elif all_data_standard_classes[i] == 'H':\n",
    "        plt.scatter(row[0],row[1], color='green')\n",
    "    elif all_data_standard_classes[i] == 'L':\n",
    "        plt.scatter(row[0],row[1], color='blue')\n",
    "    elif all_data_standard_classes[i] == 'L/LL':\n",
    "        plt.scatter(row[0],row[1], color='yellow')\n",
    "    elif all_data_standard_classes[i] == 'LL':\n",
    "        plt.scatter(row[0],row[1], color='purple')\n",
    "#plt.xlim(-2,0)\n",
    "plt.show()\n",
    "#plt.savefig('../results/PCA_5_cat')\n",
    " \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for i, row in enumerate(data_r): \n",
    "    if all_data_standard_classes[i] == 'HH': \n",
    "        plt.scatter(row[0],row[1], color='red')\n",
    "    elif all_data_standard_classes[i] == 'H':\n",
    "        continue\n",
    "    elif all_data_standard_classes[i] == 'L':\n",
    "        plt.scatter(row[0],row[1], color='blue')\n",
    "    elif all_data_standard_classes[i] == 'L/LL':\n",
    "        plt.scatter(row[0],row[1], color='yellow')\n",
    "    elif all_data_standard_classes[i] == 'LL':\n",
    "        plt.scatter(row[0],row[1], color='purple')\n",
    "#plt.xlim(-2,1)\n",
    "plt.show()\n",
    "#plt.savefig('../results/PCA_4_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for i, row in enumerate(data_r): \n",
    "    if all_data_standard_classes[i] == 'H':\n",
    "        continue\n",
    "    elif all_data_standard_classes[i] == 'L':\n",
    "        plt.scatter(row[0],row[1], color='blue')\n",
    "    elif all_data_standard_classes[i] == 'L/LL':\n",
    "        plt.scatter(row[0],row[1], color='blue')\n",
    "    elif all_data_standard_classes[i] == 'LL':\n",
    "        plt.scatter(row[0],row[1], color='blue')\n",
    "    elif all_data_standard_classes[i] == 'HH': \n",
    "        plt.scatter(row[0],row[1], color='red')\n",
    "#plt.xlim(-3,0)\n",
    "plt.show()\n",
    "#plt.savefig('../results/PCA_HHv3Ls')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, row in enumerate(data_r): \n",
    "    plt.scatter(row[0],row[1], color=COLORS[all_data_meteorite_classes[i]])\n",
    "plt.show()\n",
    "#plt.savefig('../results/PCA_meteorite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next: MNF\n",
    "#Then: MDA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
