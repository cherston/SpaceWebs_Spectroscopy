{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pysptools.util as util\n",
    "import pysptools.eea as eea\n",
    "import pysptools.classification as clssf\n",
    "import pysptools.abundance_maps as amap\n",
    "import pysptools.noise.dnoise as denoise\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataCubes = np.load('meteoriteDataCubes.npy').item()\n",
    "backgroundCubes = np.load('backgroundDataCubes.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addBackgroundColumnsToData(): \n",
    "    for sample in dataCubes: \n",
    "        BlackBackground = np.repeat([[backgroundCubes['CallibrationReadingFar']]], len(dataCubes[sample]), axis=0); \n",
    "        Velvet = np.repeat([[backgroundCubes['VelvetFar']]], len(dataCubes[sample]), axis=0); \n",
    "        dataWithBackground = np.concatenate((dataCubes[sample],BlackBackground,Velvet), axis=1)\n",
    "        dataCubesWithBackground[sample] = dataWithBackground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataCubesWithBackground = {}\n",
    "addBackgroundColumnsToData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNormalizationMaxVals(cube):\n",
    "    samples = []\n",
    "    for sample in cube:\n",
    "        for row in cube[sample]:\n",
    "            samples.append(row)\n",
    "    samples = np.reshape(samples,(867,6))\n",
    "    return np.max(np.transpose(samples), axis=1)\n",
    "     \n",
    "    #np.reshape(samples, (51,17,6))\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NormalizationMaxVals = getNormalizationMaxVals(dataCubesWithBackground)\n",
    "print NormalizationMaxVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NormalizeCubePerColumn(cube):\n",
    "    normalized_cube = cube \n",
    "    print NormalizationMaxVals\n",
    "    for sample in normalized_cube: \n",
    "        for i, row in enumerate(normalized_cube[sample]): \n",
    "            normalized_cube[sample][i] = normalized_cube[sample][i] /  NormalizationMaxVals\n",
    "    #print cube\n",
    "    return normalized_cube\n",
    "#print dataCubesWithBackground['Allende']\n",
    "normalizedDataCubesWithBackground = NormalizeCubePerColumn(dataCubesWithBackground)      \n",
    "#print normalizedDataCubesWithBackground['Allende']\n",
    "print dataCubesWithBackground['Allende']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display spectral lines \n",
    "#for sample in dataCubes: \n",
    "#    util.display_linear_stretch(dataCubes[sample],1,3,5)\n",
    "    #spectral_lines = util.convert2d(sample); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taken from: https://www.quora.com/How-do-I-generate-n-visually-distinct-RGB-colours-in-Python\n",
    "def get_spaced_colors(n):\n",
    "    max_value = 16581375 #255**3\n",
    "    interval = int(max_value / n)\n",
    "    colors = [hex(I)[2:].zfill(6) for I in range(0, max_value, interval)]\n",
    "    \n",
    "    return [(int(i[:2], 16), int(i[2:4], 16), int(i[4:], 16)) for i in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ATGP(sample):  \n",
    "    ATGP = eea.ATGP()\n",
    "    ATGP.extract(sample,q=2)\n",
    "    return ATGP.get_idx()\n",
    "    #ATGP.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NFINDR(sample): \n",
    "    NFINDR = eea.NFINDR()\n",
    "    NFINDR.extract(sample, q=2)\n",
    "    return NFINDR.get_idx()\n",
    "    #NFINDR.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FIPPI(sample):\n",
    "    FIPPI = eea.FIPPI()\n",
    "    FIPPI.extract(sample, q=2)\n",
    "    return FIPPI.get_idx()\n",
    "    #NFINDR.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PPI(sample):\n",
    "    PPI = eea.PPI()\n",
    "    PPI.extract(sample, q=2)\n",
    "    return PPI.get_idx()\n",
    "    #NFINDR.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Endmembers per row\n",
    "def endmembersPerRow(cube):\n",
    "    for sample in cube: \n",
    "        print sample + ':'\n",
    "        for i, row in enumerate(cube[sample]): \n",
    "            print \"row \" + str(i) + \":\"  \n",
    "            print \"row shape: \" + str(np.shape(row))\n",
    "            print ATGP(np.array([row]))\n",
    "            print NFINDR(np.array([row]))\n",
    "            print PPI(np.array([row]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Endmembers per sample\n",
    "ATGP_dict = {}\n",
    "NFINDR_dict = {}\n",
    "PPI_dict = {}\n",
    "\n",
    "\n",
    "for sample in dataCubesWithBackground: \n",
    "        ATGP_dict[sample] = ATGP(dataCubesWithBackground[sample])\n",
    "        NFINDR_dict[sample] = NFINDR(dataCubesWithBackground[sample])\n",
    "        PPI_dict[sample] = PPI(dataCubesWithBackground[sample])\n",
    "        \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#endmembers per sample where endmember algorithms are run with normalized data \n",
    "\n",
    "ATGP_normalized_dict = {}\n",
    "NFINDR_normalized_dict = {}\n",
    "PPI_normalized_dict = {}\n",
    "for sample in normalizedDataCubesWithBackground: \n",
    "        ATGP_normalized_dict[sample] = ATGP(normalizedDataCubesWithBackground[sample])\n",
    "        NFINDR_normalized_dict[sample] = NFINDR(normalizedDataCubesWithBackground[sample])\n",
    "        PPI_normalized_dict[sample] = PPI(normalizedDataCubesWithBackground[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endmember_dicts = {'ATGP':ATGP_dict, 'NFINDR':NFINDR_dict, 'PPI':PPI_dict}\n",
    "endmember_normalized_dicts = {'ATGP':ATGP_normalized_dict, 'NFINDR':NFINDR_normalized_dict, 'PPI':PPI_normalized_dict}\n",
    "#np.save('endmember_dicts.npy', endmember_dicts)\n",
    "#np.save('endmember_normalized_dicts.npy', endmember_normalized_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "colors = get_spaced_colors(100) \n",
    "band = np.array([610,680,730,760,810,860])\n",
    "endmember_colors = ['yellow','orange','lime']\n",
    "\n",
    "def SpectralPlotsWithEndmembers(cube,algorithm,my_endmember_dict):\n",
    "    endmember_dict = my_endmember_dict[algorithm]; \n",
    "    background = np.array(backgroundCubes['CallibrationReadingFar']) / NormalizationMaxVals\n",
    "    for sample in cube: \n",
    "        #print sample\n",
    "        linearized = util.convert2d(cube[sample])       \n",
    "        for i, (a,b) in enumerate(endmember_dict[sample]): \n",
    "            plt.plot(band,cube[sample][b][a],color=endmember_colors[i], linewidth='8')\n",
    "            #print str((a,b)) + ': ' + endmember_colors[i]\n",
    "        plt.plot(band,np.transpose(linearized))\n",
    "       \n",
    "        print backgroundCubes['CallibrationReadingFar']\n",
    "        print background\n",
    "        plt.plot(band,background,color='black',linewidth='3')\n",
    "        #plt.plot(band,backgroundCubes['VelvetFar']/getNormalizationMaxVals(cube),color='black',linewidth='3')\n",
    "        title = '%s.pdf', sample\n",
    "        #plt.show()\n",
    "        #plt.savefig('../Results/EndmembersNormalized/' + algorithm + '/' + sample + '.pdf')\n",
    "        plt.clf()\n",
    "\n",
    "print endmember_normalized_dicts['ATGP']['Soku']\n",
    "#SpectralPlotsWithEndmembers(normalizedDataCubesWithBackground, 'ATGP',endmember_normalized_dicts)\n",
    "#SpectralPlotsWithEndmembers(normalizedDataCubesWithBackground, 'NFINDR',endmember_normalized_dicts)\n",
    "#SpectralPlotsWithEndmembers(normalizedDataCubesWithBackground, 'PPI',endmember_normalized_dicts)\n",
    "SpectralPlotsWithEndmembers(dataCubesWithBackground, 'ATGP',endmember_dicts)\n",
    "SpectralPlotsWithEndmembers(dataCubesWithBackground, 'NFINDR',endmember_dicts)\n",
    "SpectralPlotsWithEndmembers(dataCubesWithBackground, 'PPI',endmember_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DECISION: USE ENDMEMBERS SUPPLIED BY NFINDR ALGORITHM \n",
    "fully_constrained_abundance_map_dict = {}\n",
    "\n",
    "def makeAbundanceMaps(cube,endmember_dicts):\n",
    "    for sample in cube:\n",
    "        data = cube[sample]\n",
    "        endmember_indices = NFINDR_dict[sample]\n",
    "        endmembers = np.array([data[b][a] for (a,b) in endmember_indices])\n",
    "\n",
    "        unmixed_unconstrained = amap.UCLS()\n",
    "        unconstrained_abundance_map = unmixed_unconstrained.map(data, endmembers) \n",
    "\n",
    "        unmixed_nonnegative_constrained = amap.NNLS()\n",
    "        nonnegative_abundance_map = unmixed_nonnegative_constrained.map(data, endmembers) \n",
    "\n",
    "        unmixed_fully_constrained = amap.FCLS()\n",
    "        fully_constrained_abundance_map = unmixed_fully_constrained.map(data, endmembers) \n",
    "        fully_constrained_abundance_map_dict[sample] = fully_constrained_abundance_map\n",
    "        #os.mkdir('./' + sample)\n",
    "        #unmixed_fully_constrained.plot('./' + sample)\n",
    "makeAbundanceMaps(normalizedDataCubesWithBackground,endmember_normalized_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#small hack to determine which endmember corresponds to the black background based on me \n",
    "#manually adding a column of black pixels to the data array\n",
    "\n",
    "def whichisblack(abundance_map):\n",
    "    black = 0\n",
    "    #print \"which is black? \" + str(abundance_map[0][16][0]) + 'vs.' + str(abundance_map[0][16][1])\n",
    "    if abundance_map[0][16][0] > 0.94:\n",
    "        return 0\n",
    "    elif abundance_map[0][16][1] > 0.94: \n",
    "        return 1\n",
    "    else:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NEXT DECISION: USE FULLY CONSTRAINED MAP (IE NON NEGATIVE AND SUMS TO 1)\n",
    "\n",
    "pure_signal_dict = {}\n",
    "black_endmember = backgroundCubes['CallibrationReadingFar'] \n",
    "normalized_black_endmember = backgroundCubes['CallibrationReadingFar'] / NormalizationMaxVals\n",
    "def extractSignalFromBackground(cube,endmember_dict,my_black_endmember):\n",
    "    for sample in cube: \n",
    "        #note that this dict is set based on how makeabundancemap function above is run (ie/normalized vs not)\n",
    "        abundance_map = fully_constrained_abundance_map_dict[sample]\n",
    "        endmember_indices = endmember_dict[sample]\n",
    "        data = dataCubesWithBackground[sample]\n",
    "        endmembers = np.array([data[b][a] for (a,b) in endmember_indices])\n",
    "\n",
    "        #print abundance_map\n",
    "        black = whichisblack(abundance_map)\n",
    "        #print black\n",
    "        if black == 0:\n",
    "            signal = 1\n",
    "        else:\n",
    "            signal = 0\n",
    "\n",
    "        pixels = []\n",
    "        for i, row in enumerate(cube[sample]): \n",
    "            for j, pixel in enumerate(row): \n",
    "                #print pixel\n",
    "                #note how below I'm using my far reading endmember for all samples. Could be worth correcting\n",
    "                #but based on the plots I've seen, the black readings are close enough to each other relative to signal\n",
    "                #that I'm not extremely worried for my first round of analysis \n",
    "                #print i\n",
    "                #print j\n",
    "                #print signal\n",
    "                if abundance_map[i][j][signal] > 0.75:\n",
    "                    extracted_signal_in_pixel = (cube[sample][i][j] - abundance_map[i][j][black] * my_black_endmember ) / abundance_map[i][j][signal]\n",
    "                    pixels.append(extracted_signal_in_pixel)\n",
    "        pure_signal_dict[sample] = pixels\n",
    "\n",
    "extractSignalFromBackground(normalizedDataCubesWithBackground,endmember_normalized_dicts['NFINDR'],normalized_black_endmember)  \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('pure_signal_dict.npy', pure_signal_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = get_spaced_colors(100) \n",
    "band = np.array([610,680,730,760,810,860])\n",
    "#highestthreshold: 0.85\n",
    "#highthreshold: 0.75\n",
    "#lowthreshold: 0.5\n",
    "def plotExtractedSignals(pure_signal_dict):\n",
    "    print len(pure_signal_dict)\n",
    "    for sample in pure_signal_dict:\n",
    "        plt.clf()\n",
    "        data = pure_signal_dict[sample]\n",
    "        print sample\n",
    "        print np.shape(data)\n",
    "        plt.plot(band,np.transpose(data))\n",
    "        plt.title(sample)\n",
    "        #plt.ylim([0,1])\n",
    "        #plt.show()\n",
    "        #os.mkdir('./' + sample)\n",
    "        plt.savefig('../Results/NormalizedExtractedSignalsHighThreshold/' + sample + '.pdf')\n",
    "         \n",
    "\n",
    "plotExtractedSignals(pure_signal_dict)\n",
    "#plotPureSignals(pure_signal_dict)\n",
    "#NOTE: HORRIBLE HORRIBLE RESULTS!!! Maybe try just non negative constrained? \n",
    "#DECISION FOR NOW: USE CLASSIFICATION INSTEAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purest_pixels_dict = {}\n",
    "\n",
    "def populatePurestPixelsDict(cube):\n",
    "    classification = clssf.AbundanceClassification()\n",
    "    for sample in cube:\n",
    "        abundancemap = fully_constrained_abundance_map_dict[sample]\n",
    "        classified_pixels = classification.classify(abundancemap,0.3)\n",
    "\n",
    "        black = classified_pixels[0][16]\n",
    "        if black == 2: \n",
    "            signal = 1\n",
    "        else:\n",
    "            signal = 2\n",
    "        pixel_array = []\n",
    "        for i,row in enumerate(classified_pixels): \n",
    "            for j,column in enumerate(row):\n",
    "                if classified_pixels[i][j] == signal: \n",
    "                    pixel_array.append(cube[sample][i][j])\n",
    "        purest_pixels_dict[sample] = pixel_array\n",
    "    #classification.plot('./ExtractedSignals/' + sample + '/')\n",
    "#print np.shape(dataCubesWithBackground['Allende'])\n",
    "#print np.shape(purest_pixels_dict['Allende'])\n",
    "populatePurestPixelsDict(normalizedDataCubesWithBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_purest_pixels(purest_pixels_dict):\n",
    "    for sample in purest_pixels_dict: \n",
    "        plt.plot(band,np.transpose(purest_pixels_dict[sample]))\n",
    "        #plt.show()\n",
    "        plt.savefig('../Results/NormalizedPurestPixels2/' + sample)\n",
    "        plt.clf()\n",
    "        \n",
    "plot_purest_pixels(purest_pixels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('purest_pixels_dict.npy', purest_pixels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samplelist = []\n",
    "def getNormalizationMaxVals(purest_pixels_dict):\n",
    "    for sample in purest_pixels_dict:\n",
    "        for row in purest_pixels_dict[sample]:\n",
    "            samplelist.append(row)\n",
    "    return np.array(np.amax(samplelist, axis=0))\n",
    "getNormalizationMaxVals(purest_pixels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_purest_pixels_normalized(purest_pixels_dict):\n",
    "    max_vals = NormalizationMaxVals\n",
    "    #print np.shape(max_vals)\n",
    "    for sample in purest_pixels_dict: \n",
    "        normalized_data = np.array(purest_pixels_dict[sample]) / np.array(max_vals)\n",
    "        normalized_data_transpose = np.transpose(normalized_data)\n",
    "        #print np.shape(normalized_data_transpose)\n",
    "        plt.plot(band,normalized_data_transpose)\n",
    "        #plt.show()\n",
    "        #os.mkdir('./Results/PurestPixelsNormalized/' + sample)\n",
    "        #plt.savefig('../Results/LateNormalizedPurestPixels2/' + sample)\n",
    "        plt.clf()\n",
    "        \n",
    "plot_purest_pixels_normalized(purest_pixels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1000,2000,3000,4000,5000,6000],[1000,2000,3000,4000,5000,6000]  \n",
    "#print np.shape(a)\n",
    "#print np.shape([getNormalizationMaxVals(purest_pixels_dict)])\n",
    "print \"max vals: \" + str(getNormalizationMaxVals(purest_pixels_dict))\n",
    "data = getNormalizationMaxVals(purest_pixels_dict)\n",
    "print np.divide(a,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
